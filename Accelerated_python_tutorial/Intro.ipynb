{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f8b742e",
   "metadata": {},
   "source": [
    "## Video Segmentation Pipeline for Background Blurring\n",
    "\n",
    "Let's practice the optimization workflow with Nsight Systems on a sample application which uses AI to blur the background in videos. It is most commonly used in video conferencing software.\n",
    "\n",
    "<img src=images/Background_blurring.jpg width=40%>\n",
    "\n",
    "The input video is of a cat courtesy of Ilimdar Avgezer. The Video is of 1080p resolution andÂ it consists of 474 frames. Execute the cell below to view the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b36a2f80-f5b6-4a3d-a975-c37c3e4cb991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"pexels-ilimdar-avgezer-7081456.mp4\" controls  width=\"640\"  height=\"480\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"pexels-ilimdar-avgezer-7081456.mp4\", width=640, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bf88e2-49b0-4c70-b71e-c059b6a63217",
   "metadata": {},
   "source": [
    "The idea behind background blurring is to use a ResNet101 segmentation network to detect the object in each frame, create a mask, and use the mask to combine the original image and a blurred version of it. The algorithm is shown as a block diagram below.\n",
    "\n",
    "<img src=images/Video_segmentation_sample.jpg width=70%>\n",
    "\n",
    "Every frame goes through essentially 5 steps as illustrated in the diagram below. \n",
    "\n",
    "<img src=images/Full_pipeline.jpg width=70%>\n",
    "\n",
    "We will start with a baseline code in Python that uses the following components. You can view the code by opening the file [main.py](video_segmentation/main.py).\n",
    "1. [ffmpeg](https://ffmpeg.org/) for the decoding and encoding steps\n",
    "2. [OpenCV](https://pypi.org/project/opencv-python/) for the pre-processing and post-processing\n",
    "3. and [PyTorch](https://pytorch.org/) for the segmentation DNN. The frames are grouped into batches of four.\n",
    "\n",
    "Let's optimize this application using Nsight Systems. The tips and strategies discussed in this lab will apply to optimizing any other application.\n",
    "\n",
    "Please click on [step 1](step1.ipynb) to open the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
