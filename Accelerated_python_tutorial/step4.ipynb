{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a339e968",
   "metadata": {},
   "source": [
    "## Step 4: Multi-Report Analysis\n",
    "\n",
    "In this notebook, we will learn about Nsight Systems' multi-report analysis.\n",
    "\n",
    "When profiling parallel applications, it might be sufficient to profile just one rank (or process tree) as representative of the work done on the remaining ranks.\n",
    "However, to evaluate aspects such as load balancing across nodes and ranks, communication between the nodes and ranks, etc., we need to profile all the ranks of the application.\n",
    "In such cases, you might end up with tens or hundreds of report files to analyze, which may not be practicable using the Nsight Systems timeline (even though multiple reports can be opened into a single timeline).\n",
    "\n",
    "The Nsight Systems **Multi-Report Analysis System** allows you to do **statistical analysis across multiple result files**.\n",
    "The workflow is illustrated in the following diagram.\n",
    "\n",
    "<img src=images/step4/multi_node_analysis.jpg width=70%>\n",
    "\n",
    "Nsight Systems provides a **library of Python scripts** which are referred to as **recipes**.\n",
    "The recipe analysis can be run immediately after the collection or post-mortem.\n",
    "The output is usually Jupyter notebooks that can be viewed within the Nsight Systems GUI or in a browser.\n",
    "It is intended to visually **highlight outliers** and other issues that should to be investigated further.\n",
    "\n",
    "Nsight Systems ships with several built-in recipes.\n",
    "A tutorial on how to write your own recipes is included in the [documentation](https://docs.nvidia.com/nsight-systems/UserGuide/index.html#tutorial-create-a-user-defined-recipe). We encourage users to share any custom recipes that they believe would be beneficial for the [Nsight Systems community](https://devtalk.nvidia.com/default/board/308/nsight-systems/), so we can include them in future versions of the recipe library.\n",
    "\n",
    "To see the list of available recipes that are included with Nsight Systems, execute the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "094db8d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "usage: nsys recipe [<args>] <recipe name> [<recipe args>]\n",
      "\n",
      "\t-h, --help\n",
      "\n",
      "\t    Print the command's help menu.\n",
      "\n",
      "\t-q, --quiet\n",
      "\n",
      "           Only display errors.\n",
      "\n",
      "The following built-in recipes are available:\n",
      "\n",
      "  cuda_api_sum -- CUDA API Summary\n",
      "  cuda_api_sync -- CUDA Synchronization APIs\n",
      "  cuda_gpu_kern_hist -- CUDA GPU Kernel Duration Histogram\n",
      "  cuda_gpu_kern_pace -- CUDA GPU Kernel Pacing\n",
      "  cuda_gpu_kern_sum -- CUDA GPU Kernel Summary\n",
      "  cuda_gpu_mem_size_sum -- CUDA GPU MemOps Summary (by Size)\n",
      "  cuda_gpu_mem_time_sum -- CUDA GPU MemOps Summary (by Time)\n",
      "  cuda_gpu_time_util_map -- CUDA GPU Time Utilization Heatmap\n",
      "  cuda_memcpy_async -- CUDA Async Memcpy with Pageable Memory\n",
      "  cuda_memcpy_sync -- CUDA Synchronous Memcpy\n",
      "  cuda_memset_sync -- CUDA Synchronous Memset\n",
      "  diff -- Statistics Diff\n",
      "  dx12_mem_ops -- DX12 Memory Operations\n",
      "  gpu_gaps -- GPU Gaps\n",
      "  gpu_metric_util_map -- GPU Metric Utilization Heatmap\n",
      "  gpu_metric_util_sum -- GPU Metrics Utilization Summary\n",
      "  gpu_time_util -- GPU Time Utilization\n",
      "  mpi_gpu_time_util_map -- MPI and GPU Time Utilization Heatmap\n",
      "  mpi_sum -- MPI Summary\n",
      "  nccl_gpu_overlap_trace -- NCCL GPU Overlap Trace\n",
      "  nccl_gpu_proj_sum -- NCCL GPU Projection Summary\n",
      "  nccl_gpu_time_util_map -- NCCL GPU Time Utilization Heatmap\n",
      "  nccl_sum -- NCCL Summary\n",
      "  network_map_aws -- AWS Metrics Heatmap\n",
      "  network_sum -- Network Traffic Summary\n",
      "  network_traffic_map -- Network Devices Traffic Heatmap\n",
      "  nvlink_sum -- NVLink Network Bandwidth Summary\n",
      "  nvtx_gpu_proj_pace -- NVTX GPU Projection Pacing\n",
      "  nvtx_gpu_proj_sum -- NVTX GPU Projection Summary\n",
      "  nvtx_gpu_proj_trace -- NVTX GPU Projection Trace\n",
      "  nvtx_pace -- NVTX Pacing\n",
      "  nvtx_sum -- NVTX Range Summary\n",
      "  osrt_sum -- OS Runtime Summary\n",
      "  storage_util_map -- Storage Metrics Heatmap\n",
      "  ucx_gpu_time_util_map -- UCX and GPU Time Utilization Heatmap\n",
      "\n",
      "To get help on a specific recipe, run 'nsys recipe <recipe name> --help'.\n",
      "\n",
      "Note that running 'nsys recipe <recipe name>' requires extra Python packages:\n",
      "  - List of required Python packages: '/opt/nvidia/nsight-systems/2025.1.3/target-linux-x64/python/packages/nsys_recipe/requirements/common.txt'\n",
      "  - Helper script to automate installation of dependencies: '/opt/nvidia/nsight-systems/2025.1.3/target-linux-x64/python/packages/nsys_recipe/install.py'\n",
      "\n",
      "For more information, please refer to the Nsight Systems User Guide.\n"
     ]
    }
   ],
   "source": [
    "!nsys recipe --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e2f6eb-6a89-4af6-b501-66dc3e96cd2c",
   "metadata": {},
   "source": [
    "### 4.1 NVTX GPU Projection Summary Recipe\n",
    "\n",
    "We would like to tune the input parameters so that we get the fastest execution time.\n",
    "We will focus on tuning the batch size, which reflects the number of frames that are processed as a single batch.\n",
    "The NVTX annotations that have been added to the code will help us to easily identify the **fastest pipeline** and the **most time-consuming step** in each batch execution.\n",
    "\n",
    "Execute the cell below to create profiles for the batch sizes 1, 2, 4, 8 and 16, which will result in in five report files. Be patient, this will take a little while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49e592cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: CPU IP/backtrace sampling not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "WARNING: CPU context switch tracing not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "Invalid plugin configuration: Executable path does not exist: /opt/nvidia/nsight-systems/2025.1.3/target-linux-x64/plugins/mynvml/mynvml_plugin\n",
      "Collecting data...\n",
      "Using batch size 1\n",
      "{<NV_ENC_CAPS.NUM_MAX_BFRAMES: 0>: 4, <NV_ENC_CAPS.SUPPORTED_RATECONTROL_MODES: 1>: 63, <NV_ENC_CAPS.SUPPORT_FIELD_ENCODING: 2>: 0, <NV_ENC_CAPS.SUPPORT_MONOCHROME: 3>: 0, <NV_ENC_CAPS.SUPPORT_FMO: 4>: 0, <NV_ENC_CAPS.SUPPORT_QPELMV: 5>: 1, <NV_ENC_CAPS.SUPPORT_BDIRECT_MODE: 6>: 1, <NV_ENC_CAPS.SUPPORT_CABAC: 7>: 1, <NV_ENC_CAPS.SUPPORT_ADAPTIVE_TRANSFORM: 8>: 1, <NV_ENC_CAPS.SUPPORT_STEREO_MVC: 9>: 1, <NV_ENC_CAPS.NUM_MAX_TEMPORAL_LAYERS: 10>: 4, <NV_ENC_CAPS.SUPPORT_HIERARCHICAL_PFRAMES: 11>: 1, <NV_ENC_CAPS.SUPPORT_HIERARCHICAL_BFRAMES: 12>: 1, <NV_ENC_CAPS.LEVEL_MAX: 13>: 62, <NV_ENC_CAPS.LEVEL_MIN: 14>: 10, <NV_ENC_CAPS.SEPARATE_COLOUR_PLANE: 15>: 1, <NV_ENC_CAPS.WIDTH_MAX: 16>: 4096, <NV_ENC_CAPS.HEIGHT_MAX: 17>: 4096, <NV_ENC_CAPS.SUPPORT_TEMPORAL_SVC: 18>: 1, <NV_ENC_CAPS.SUPPORT_DYN_RES_CHANGE: 19>: 1, <NV_ENC_CAPS.SUPPORT_DYN_BITRATE_CHANGE: 20>: 1, <NV_ENC_CAPS.SUPPORT_DYN_FORCE_CONSTQP: 21>: 1, <NV_ENC_CAPS.SUPPORT_DYN_RCMODE_CHANGE: 22>: 0, <NV_ENC_CAPS.SUPPORT_SUBFRAME_READBACK: 23>: 1, <NV_ENC_CAPS.SUPPORT_CONSTRAINED_ENCODING: 24>: 1, <NV_ENC_CAPS.SUPPORT_INTRA_REFRESH: 25>: 1, <NV_ENC_CAPS.SUPPORT_CUSTOM_VBV_BUF_SIZE: 26>: 1, <NV_ENC_CAPS.SUPPORT_DYNAMIC_SLICE_MODE: 27>: 1, <NV_ENC_CAPS.SUPPORT_REF_PIC_INVALIDATION: 28>: 1, <NV_ENC_CAPS.PREPROC_SUPPORT: 29>: 0, <NV_ENC_CAPS.ASYNC_ENCODE_SUPPORT: 30>: 0, <NV_ENC_CAPS.MB_NUM_MAX: 31>: 65536, <NV_ENC_CAPS.MB_PER_SEC_MAX: 32>: 983040, <NV_ENC_CAPS.SUPPORT_YUV444_ENCODE: 33>: 1, <NV_ENC_CAPS.SUPPORT_LOSSLESS_ENCODE: 34>: 1, <NV_ENC_CAPS.SUPPORT_SAO: 35>: 0, <NV_ENC_CAPS.SUPPORT_MEONLY_MODE: 36>: 1, <NV_ENC_CAPS.SUPPORT_LOOKAHEAD: 37>: 1, <NV_ENC_CAPS.SUPPORT_TEMPORAL_AQ: 38>: 1, <NV_ENC_CAPS.SUPPORT_10BIT_ENCODE: 39>: 0, <NV_ENC_CAPS.NUM_MAX_LTR_FRAMES: 40>: 8, <NV_ENC_CAPS.SUPPORT_WEIGHTED_PREDICTION: 41>: 1, <NV_ENC_CAPS.DYNAMIC_QUERY_ENCODER_CAPACITY: 42>: 100, <NV_ENC_CAPS.SUPPORT_BFRAME_REF_MODE: 43>: 3, <NV_ENC_CAPS.SUPPORT_EMPHASIS_LEVEL_MAP: 44>: 1, <NV_ENC_CAPS.WIDTH_MIN: 45>: 145, <NV_ENC_CAPS.HEIGHT_MIN: 46>: 49, <NV_ENC_CAPS.SUPPORT_MULTIPLE_REF_FRAMES: 47>: 1, <NV_ENC_CAPS.SUPPORT_ALPHA_LAYER_ENCODING: 48>: 0, <NV_ENC_CAPS.???: 49>: 1, <NV_ENC_CAPS.???: 50>: 1}\n",
      "474 batches processed\n",
      "Generating '/tmp/nsys-report-e791.qdstrm'\n",
      "[1/1] [========================100%] cvcuda_bs01.nsys-rep\n",
      "Generated:\n",
      "\t/home/sanjay42/sanjay/cuda/AcceleratedPythonProgramming/reports/cvcuda_batchsize/cvcuda_bs01.nsys-rep\n",
      "WARNING: CPU IP/backtrace sampling not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "WARNING: CPU context switch tracing not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "Invalid plugin configuration: Executable path does not exist: /opt/nvidia/nsight-systems/2025.1.3/target-linux-x64/plugins/mynvml/mynvml_plugin\n",
      "Collecting data...\n",
      "Using batch size 2\n",
      "{<NV_ENC_CAPS.NUM_MAX_BFRAMES: 0>: 4, <NV_ENC_CAPS.SUPPORTED_RATECONTROL_MODES: 1>: 63, <NV_ENC_CAPS.SUPPORT_FIELD_ENCODING: 2>: 0, <NV_ENC_CAPS.SUPPORT_MONOCHROME: 3>: 0, <NV_ENC_CAPS.SUPPORT_FMO: 4>: 0, <NV_ENC_CAPS.SUPPORT_QPELMV: 5>: 1, <NV_ENC_CAPS.SUPPORT_BDIRECT_MODE: 6>: 1, <NV_ENC_CAPS.SUPPORT_CABAC: 7>: 1, <NV_ENC_CAPS.SUPPORT_ADAPTIVE_TRANSFORM: 8>: 1, <NV_ENC_CAPS.SUPPORT_STEREO_MVC: 9>: 1, <NV_ENC_CAPS.NUM_MAX_TEMPORAL_LAYERS: 10>: 4, <NV_ENC_CAPS.SUPPORT_HIERARCHICAL_PFRAMES: 11>: 1, <NV_ENC_CAPS.SUPPORT_HIERARCHICAL_BFRAMES: 12>: 1, <NV_ENC_CAPS.LEVEL_MAX: 13>: 62, <NV_ENC_CAPS.LEVEL_MIN: 14>: 10, <NV_ENC_CAPS.SEPARATE_COLOUR_PLANE: 15>: 1, <NV_ENC_CAPS.WIDTH_MAX: 16>: 4096, <NV_ENC_CAPS.HEIGHT_MAX: 17>: 4096, <NV_ENC_CAPS.SUPPORT_TEMPORAL_SVC: 18>: 1, <NV_ENC_CAPS.SUPPORT_DYN_RES_CHANGE: 19>: 1, <NV_ENC_CAPS.SUPPORT_DYN_BITRATE_CHANGE: 20>: 1, <NV_ENC_CAPS.SUPPORT_DYN_FORCE_CONSTQP: 21>: 1, <NV_ENC_CAPS.SUPPORT_DYN_RCMODE_CHANGE: 22>: 0, <NV_ENC_CAPS.SUPPORT_SUBFRAME_READBACK: 23>: 1, <NV_ENC_CAPS.SUPPORT_CONSTRAINED_ENCODING: 24>: 1, <NV_ENC_CAPS.SUPPORT_INTRA_REFRESH: 25>: 1, <NV_ENC_CAPS.SUPPORT_CUSTOM_VBV_BUF_SIZE: 26>: 1, <NV_ENC_CAPS.SUPPORT_DYNAMIC_SLICE_MODE: 27>: 1, <NV_ENC_CAPS.SUPPORT_REF_PIC_INVALIDATION: 28>: 1, <NV_ENC_CAPS.PREPROC_SUPPORT: 29>: 0, <NV_ENC_CAPS.ASYNC_ENCODE_SUPPORT: 30>: 0, <NV_ENC_CAPS.MB_NUM_MAX: 31>: 65536, <NV_ENC_CAPS.MB_PER_SEC_MAX: 32>: 983040, <NV_ENC_CAPS.SUPPORT_YUV444_ENCODE: 33>: 1, <NV_ENC_CAPS.SUPPORT_LOSSLESS_ENCODE: 34>: 1, <NV_ENC_CAPS.SUPPORT_SAO: 35>: 0, <NV_ENC_CAPS.SUPPORT_MEONLY_MODE: 36>: 1, <NV_ENC_CAPS.SUPPORT_LOOKAHEAD: 37>: 1, <NV_ENC_CAPS.SUPPORT_TEMPORAL_AQ: 38>: 1, <NV_ENC_CAPS.SUPPORT_10BIT_ENCODE: 39>: 0, <NV_ENC_CAPS.NUM_MAX_LTR_FRAMES: 40>: 8, <NV_ENC_CAPS.SUPPORT_WEIGHTED_PREDICTION: 41>: 1, <NV_ENC_CAPS.DYNAMIC_QUERY_ENCODER_CAPACITY: 42>: 100, <NV_ENC_CAPS.SUPPORT_BFRAME_REF_MODE: 43>: 3, <NV_ENC_CAPS.SUPPORT_EMPHASIS_LEVEL_MAP: 44>: 1, <NV_ENC_CAPS.WIDTH_MIN: 45>: 145, <NV_ENC_CAPS.HEIGHT_MIN: 46>: 49, <NV_ENC_CAPS.SUPPORT_MULTIPLE_REF_FRAMES: 47>: 1, <NV_ENC_CAPS.SUPPORT_ALPHA_LAYER_ENCODING: 48>: 0, <NV_ENC_CAPS.???: 49>: 1, <NV_ENC_CAPS.???: 50>: 1}\n",
      "237 batches processed\n",
      "Generating '/tmp/nsys-report-cab4.qdstrm'\n",
      "[1/1] [========================100%] cvcuda_bs02.nsys-rep\n",
      "Generated:\n",
      "\t/home/sanjay42/sanjay/cuda/AcceleratedPythonProgramming/reports/cvcuda_batchsize/cvcuda_bs02.nsys-rep\n",
      "WARNING: CPU IP/backtrace sampling not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "WARNING: CPU context switch tracing not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "Invalid plugin configuration: Executable path does not exist: /opt/nvidia/nsight-systems/2025.1.3/target-linux-x64/plugins/mynvml/mynvml_plugin\n",
      "Collecting data...\n",
      "Using batch size 4\n",
      "{<NV_ENC_CAPS.NUM_MAX_BFRAMES: 0>: 4, <NV_ENC_CAPS.SUPPORTED_RATECONTROL_MODES: 1>: 63, <NV_ENC_CAPS.SUPPORT_FIELD_ENCODING: 2>: 0, <NV_ENC_CAPS.SUPPORT_MONOCHROME: 3>: 0, <NV_ENC_CAPS.SUPPORT_FMO: 4>: 0, <NV_ENC_CAPS.SUPPORT_QPELMV: 5>: 1, <NV_ENC_CAPS.SUPPORT_BDIRECT_MODE: 6>: 1, <NV_ENC_CAPS.SUPPORT_CABAC: 7>: 1, <NV_ENC_CAPS.SUPPORT_ADAPTIVE_TRANSFORM: 8>: 1, <NV_ENC_CAPS.SUPPORT_STEREO_MVC: 9>: 1, <NV_ENC_CAPS.NUM_MAX_TEMPORAL_LAYERS: 10>: 4, <NV_ENC_CAPS.SUPPORT_HIERARCHICAL_PFRAMES: 11>: 1, <NV_ENC_CAPS.SUPPORT_HIERARCHICAL_BFRAMES: 12>: 1, <NV_ENC_CAPS.LEVEL_MAX: 13>: 62, <NV_ENC_CAPS.LEVEL_MIN: 14>: 10, <NV_ENC_CAPS.SEPARATE_COLOUR_PLANE: 15>: 1, <NV_ENC_CAPS.WIDTH_MAX: 16>: 4096, <NV_ENC_CAPS.HEIGHT_MAX: 17>: 4096, <NV_ENC_CAPS.SUPPORT_TEMPORAL_SVC: 18>: 1, <NV_ENC_CAPS.SUPPORT_DYN_RES_CHANGE: 19>: 1, <NV_ENC_CAPS.SUPPORT_DYN_BITRATE_CHANGE: 20>: 1, <NV_ENC_CAPS.SUPPORT_DYN_FORCE_CONSTQP: 21>: 1, <NV_ENC_CAPS.SUPPORT_DYN_RCMODE_CHANGE: 22>: 0, <NV_ENC_CAPS.SUPPORT_SUBFRAME_READBACK: 23>: 1, <NV_ENC_CAPS.SUPPORT_CONSTRAINED_ENCODING: 24>: 1, <NV_ENC_CAPS.SUPPORT_INTRA_REFRESH: 25>: 1, <NV_ENC_CAPS.SUPPORT_CUSTOM_VBV_BUF_SIZE: 26>: 1, <NV_ENC_CAPS.SUPPORT_DYNAMIC_SLICE_MODE: 27>: 1, <NV_ENC_CAPS.SUPPORT_REF_PIC_INVALIDATION: 28>: 1, <NV_ENC_CAPS.PREPROC_SUPPORT: 29>: 0, <NV_ENC_CAPS.ASYNC_ENCODE_SUPPORT: 30>: 0, <NV_ENC_CAPS.MB_NUM_MAX: 31>: 65536, <NV_ENC_CAPS.MB_PER_SEC_MAX: 32>: 983040, <NV_ENC_CAPS.SUPPORT_YUV444_ENCODE: 33>: 1, <NV_ENC_CAPS.SUPPORT_LOSSLESS_ENCODE: 34>: 1, <NV_ENC_CAPS.SUPPORT_SAO: 35>: 0, <NV_ENC_CAPS.SUPPORT_MEONLY_MODE: 36>: 1, <NV_ENC_CAPS.SUPPORT_LOOKAHEAD: 37>: 1, <NV_ENC_CAPS.SUPPORT_TEMPORAL_AQ: 38>: 1, <NV_ENC_CAPS.SUPPORT_10BIT_ENCODE: 39>: 0, <NV_ENC_CAPS.NUM_MAX_LTR_FRAMES: 40>: 8, <NV_ENC_CAPS.SUPPORT_WEIGHTED_PREDICTION: 41>: 1, <NV_ENC_CAPS.DYNAMIC_QUERY_ENCODER_CAPACITY: 42>: 100, <NV_ENC_CAPS.SUPPORT_BFRAME_REF_MODE: 43>: 3, <NV_ENC_CAPS.SUPPORT_EMPHASIS_LEVEL_MAP: 44>: 1, <NV_ENC_CAPS.WIDTH_MIN: 45>: 145, <NV_ENC_CAPS.HEIGHT_MIN: 46>: 49, <NV_ENC_CAPS.SUPPORT_MULTIPLE_REF_FRAMES: 47>: 1, <NV_ENC_CAPS.SUPPORT_ALPHA_LAYER_ENCODING: 48>: 0, <NV_ENC_CAPS.???: 49>: 1, <NV_ENC_CAPS.???: 50>: 1}\n",
      "119 batches processed\n",
      "Generating '/tmp/nsys-report-e700.qdstrm'\n",
      "[1/1] [========================100%] cvcuda_bs04.nsys-rep\n",
      "Generated:\n",
      "\t/home/sanjay42/sanjay/cuda/AcceleratedPythonProgramming/reports/cvcuda_batchsize/cvcuda_bs04.nsys-rep\n",
      "WARNING: CPU IP/backtrace sampling not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "WARNING: CPU context switch tracing not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "Invalid plugin configuration: Executable path does not exist: /opt/nvidia/nsight-systems/2025.1.3/target-linux-x64/plugins/mynvml/mynvml_plugin\n",
      "Collecting data...\n",
      "Using batch size 8\n",
      "{<NV_ENC_CAPS.NUM_MAX_BFRAMES: 0>: 4, <NV_ENC_CAPS.SUPPORTED_RATECONTROL_MODES: 1>: 63, <NV_ENC_CAPS.SUPPORT_FIELD_ENCODING: 2>: 0, <NV_ENC_CAPS.SUPPORT_MONOCHROME: 3>: 0, <NV_ENC_CAPS.SUPPORT_FMO: 4>: 0, <NV_ENC_CAPS.SUPPORT_QPELMV: 5>: 1, <NV_ENC_CAPS.SUPPORT_BDIRECT_MODE: 6>: 1, <NV_ENC_CAPS.SUPPORT_CABAC: 7>: 1, <NV_ENC_CAPS.SUPPORT_ADAPTIVE_TRANSFORM: 8>: 1, <NV_ENC_CAPS.SUPPORT_STEREO_MVC: 9>: 1, <NV_ENC_CAPS.NUM_MAX_TEMPORAL_LAYERS: 10>: 4, <NV_ENC_CAPS.SUPPORT_HIERARCHICAL_PFRAMES: 11>: 1, <NV_ENC_CAPS.SUPPORT_HIERARCHICAL_BFRAMES: 12>: 1, <NV_ENC_CAPS.LEVEL_MAX: 13>: 62, <NV_ENC_CAPS.LEVEL_MIN: 14>: 10, <NV_ENC_CAPS.SEPARATE_COLOUR_PLANE: 15>: 1, <NV_ENC_CAPS.WIDTH_MAX: 16>: 4096, <NV_ENC_CAPS.HEIGHT_MAX: 17>: 4096, <NV_ENC_CAPS.SUPPORT_TEMPORAL_SVC: 18>: 1, <NV_ENC_CAPS.SUPPORT_DYN_RES_CHANGE: 19>: 1, <NV_ENC_CAPS.SUPPORT_DYN_BITRATE_CHANGE: 20>: 1, <NV_ENC_CAPS.SUPPORT_DYN_FORCE_CONSTQP: 21>: 1, <NV_ENC_CAPS.SUPPORT_DYN_RCMODE_CHANGE: 22>: 0, <NV_ENC_CAPS.SUPPORT_SUBFRAME_READBACK: 23>: 1, <NV_ENC_CAPS.SUPPORT_CONSTRAINED_ENCODING: 24>: 1, <NV_ENC_CAPS.SUPPORT_INTRA_REFRESH: 25>: 1, <NV_ENC_CAPS.SUPPORT_CUSTOM_VBV_BUF_SIZE: 26>: 1, <NV_ENC_CAPS.SUPPORT_DYNAMIC_SLICE_MODE: 27>: 1, <NV_ENC_CAPS.SUPPORT_REF_PIC_INVALIDATION: 28>: 1, <NV_ENC_CAPS.PREPROC_SUPPORT: 29>: 0, <NV_ENC_CAPS.ASYNC_ENCODE_SUPPORT: 30>: 0, <NV_ENC_CAPS.MB_NUM_MAX: 31>: 65536, <NV_ENC_CAPS.MB_PER_SEC_MAX: 32>: 983040, <NV_ENC_CAPS.SUPPORT_YUV444_ENCODE: 33>: 1, <NV_ENC_CAPS.SUPPORT_LOSSLESS_ENCODE: 34>: 1, <NV_ENC_CAPS.SUPPORT_SAO: 35>: 0, <NV_ENC_CAPS.SUPPORT_MEONLY_MODE: 36>: 1, <NV_ENC_CAPS.SUPPORT_LOOKAHEAD: 37>: 1, <NV_ENC_CAPS.SUPPORT_TEMPORAL_AQ: 38>: 1, <NV_ENC_CAPS.SUPPORT_10BIT_ENCODE: 39>: 0, <NV_ENC_CAPS.NUM_MAX_LTR_FRAMES: 40>: 8, <NV_ENC_CAPS.SUPPORT_WEIGHTED_PREDICTION: 41>: 1, <NV_ENC_CAPS.DYNAMIC_QUERY_ENCODER_CAPACITY: 42>: 100, <NV_ENC_CAPS.SUPPORT_BFRAME_REF_MODE: 43>: 3, <NV_ENC_CAPS.SUPPORT_EMPHASIS_LEVEL_MAP: 44>: 1, <NV_ENC_CAPS.WIDTH_MIN: 45>: 145, <NV_ENC_CAPS.HEIGHT_MIN: 46>: 49, <NV_ENC_CAPS.SUPPORT_MULTIPLE_REF_FRAMES: 47>: 1, <NV_ENC_CAPS.SUPPORT_ALPHA_LAYER_ENCODING: 48>: 0, <NV_ENC_CAPS.???: 49>: 1, <NV_ENC_CAPS.???: 50>: 1}\n",
      "60 batches processed\n",
      "Generating '/tmp/nsys-report-ca48.qdstrm'\n",
      "[1/1] [========================100%] cvcuda_bs08.nsys-rep\n",
      "Generated:\n",
      "\t/home/sanjay42/sanjay/cuda/AcceleratedPythonProgramming/reports/cvcuda_batchsize/cvcuda_bs08.nsys-rep\n",
      "WARNING: CPU IP/backtrace sampling not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "WARNING: CPU context switch tracing not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "Invalid plugin configuration: Executable path does not exist: /opt/nvidia/nsight-systems/2025.1.3/target-linux-x64/plugins/mynvml/mynvml_plugin\n",
      "Collecting data...\n",
      "Using batch size 16\n",
      "{<NV_ENC_CAPS.NUM_MAX_BFRAMES: 0>: 4, <NV_ENC_CAPS.SUPPORTED_RATECONTROL_MODES: 1>: 63, <NV_ENC_CAPS.SUPPORT_FIELD_ENCODING: 2>: 0, <NV_ENC_CAPS.SUPPORT_MONOCHROME: 3>: 0, <NV_ENC_CAPS.SUPPORT_FMO: 4>: 0, <NV_ENC_CAPS.SUPPORT_QPELMV: 5>: 1, <NV_ENC_CAPS.SUPPORT_BDIRECT_MODE: 6>: 1, <NV_ENC_CAPS.SUPPORT_CABAC: 7>: 1, <NV_ENC_CAPS.SUPPORT_ADAPTIVE_TRANSFORM: 8>: 1, <NV_ENC_CAPS.SUPPORT_STEREO_MVC: 9>: 1, <NV_ENC_CAPS.NUM_MAX_TEMPORAL_LAYERS: 10>: 4, <NV_ENC_CAPS.SUPPORT_HIERARCHICAL_PFRAMES: 11>: 1, <NV_ENC_CAPS.SUPPORT_HIERARCHICAL_BFRAMES: 12>: 1, <NV_ENC_CAPS.LEVEL_MAX: 13>: 62, <NV_ENC_CAPS.LEVEL_MIN: 14>: 10, <NV_ENC_CAPS.SEPARATE_COLOUR_PLANE: 15>: 1, <NV_ENC_CAPS.WIDTH_MAX: 16>: 4096, <NV_ENC_CAPS.HEIGHT_MAX: 17>: 4096, <NV_ENC_CAPS.SUPPORT_TEMPORAL_SVC: 18>: 1, <NV_ENC_CAPS.SUPPORT_DYN_RES_CHANGE: 19>: 1, <NV_ENC_CAPS.SUPPORT_DYN_BITRATE_CHANGE: 20>: 1, <NV_ENC_CAPS.SUPPORT_DYN_FORCE_CONSTQP: 21>: 1, <NV_ENC_CAPS.SUPPORT_DYN_RCMODE_CHANGE: 22>: 0, <NV_ENC_CAPS.SUPPORT_SUBFRAME_READBACK: 23>: 1, <NV_ENC_CAPS.SUPPORT_CONSTRAINED_ENCODING: 24>: 1, <NV_ENC_CAPS.SUPPORT_INTRA_REFRESH: 25>: 1, <NV_ENC_CAPS.SUPPORT_CUSTOM_VBV_BUF_SIZE: 26>: 1, <NV_ENC_CAPS.SUPPORT_DYNAMIC_SLICE_MODE: 27>: 1, <NV_ENC_CAPS.SUPPORT_REF_PIC_INVALIDATION: 28>: 1, <NV_ENC_CAPS.PREPROC_SUPPORT: 29>: 0, <NV_ENC_CAPS.ASYNC_ENCODE_SUPPORT: 30>: 0, <NV_ENC_CAPS.MB_NUM_MAX: 31>: 65536, <NV_ENC_CAPS.MB_PER_SEC_MAX: 32>: 983040, <NV_ENC_CAPS.SUPPORT_YUV444_ENCODE: 33>: 1, <NV_ENC_CAPS.SUPPORT_LOSSLESS_ENCODE: 34>: 1, <NV_ENC_CAPS.SUPPORT_SAO: 35>: 0, <NV_ENC_CAPS.SUPPORT_MEONLY_MODE: 36>: 1, <NV_ENC_CAPS.SUPPORT_LOOKAHEAD: 37>: 1, <NV_ENC_CAPS.SUPPORT_TEMPORAL_AQ: 38>: 1, <NV_ENC_CAPS.SUPPORT_10BIT_ENCODE: 39>: 0, <NV_ENC_CAPS.NUM_MAX_LTR_FRAMES: 40>: 8, <NV_ENC_CAPS.SUPPORT_WEIGHTED_PREDICTION: 41>: 1, <NV_ENC_CAPS.DYNAMIC_QUERY_ENCODER_CAPACITY: 42>: 100, <NV_ENC_CAPS.SUPPORT_BFRAME_REF_MODE: 43>: 3, <NV_ENC_CAPS.SUPPORT_EMPHASIS_LEVEL_MAP: 44>: 1, <NV_ENC_CAPS.WIDTH_MIN: 45>: 145, <NV_ENC_CAPS.HEIGHT_MIN: 46>: 49, <NV_ENC_CAPS.SUPPORT_MULTIPLE_REF_FRAMES: 47>: 1, <NV_ENC_CAPS.SUPPORT_ALPHA_LAYER_ENCODING: 48>: 0, <NV_ENC_CAPS.???: 49>: 1, <NV_ENC_CAPS.???: 50>: 1}\n",
      "30 batches processed\n",
      "Generating '/tmp/nsys-report-43d1.qdstrm'\n",
      "[1/1] [========================100%] cvcuda_bs16.nsys-rep\n",
      "Generated:\n",
      "\t/home/sanjay42/sanjay/cuda/AcceleratedPythonProgramming/reports/cvcuda_batchsize/cvcuda_bs16.nsys-rep\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p reports/cvcuda_batchsize\n",
    "\n",
    "!for bs in 1 2 4 8 16; do \\\n",
    "  printf -v bs_zfill \"%02d\" ${bs}; \\\n",
    "  nsys profile --trace cuda,nvtx \\\n",
    "    --cuda-event-trace=false \\\n",
    "    --output reports/cvcuda_batchsize/cvcuda_bs${bs_zfill} \\\n",
    "    --force-overwrite=true \\\n",
    "  python video_segmentation/main_nvtx-cvcuda-nvcodec.py ${bs} ; \\\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40f3e22",
   "metadata": {},
   "source": [
    "The `printf` line in the code box above creates a two-digit representation of the batch size at the end of the report file name.\n",
    "This gives us an ascending sorting of the report files by batch size, which simply reads better in the notebook output.\n",
    "\n",
    "Let's use the  **nvtx_gpu_proj_sum** recipe on the five reports in *reports/cvcuda_batchsize*.\n",
    "It will help us identify the slowest step in the algorithm.\n",
    "\n",
    "<img src=images/step4/topN_explanation.jpg width=70%>\n",
    "\n",
    "Recall that there is only one **pipeline** NVTX range in the timeline and it spans over all the batches in the workload.\n",
    "Examining the duration of this range across all report files will give us the execution time of the video segmentation pipeline.\n",
    "\n",
    "The following mockup of a timeline illustrates how NVTX ranges are projected from the CPU onto the GPU.\n",
    "\n",
    "<img src=images/step4/gpu_projection_mockup_v2.jpg width=75%>\n",
    "\n",
    "Users add NVTX ranges on the CPU thread to annotate the various phases of their code’s algorithms. Nsight Systems automatically projects a NVTX range onto the GPU by analyzing any CUDA work launched from within that range on the same CPU thread. The projection refits the range's start and end time to tightly wrap the CUDA launches, memory copies and memset operations invoked within it. You will see the NVTX projection on the GPU under the CUDA HW timeline row as highlighted in the screenshot below.\n",
    "\n",
    "<img src=images/step4/nsys-timeline-nvtx-projection_arrows.png>\n",
    "\n",
    "Execute the cell below the see the command line options for the **nvtx_gpu_proj_sum** recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca48fe1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: nvtx_gpu_proj_sum [-h] [--output OUTPUT] [--force-overwrite] --input\n",
      "                         INPUT [INPUT ...] [--csv]\n",
      "                         [--filter-time [start_time]/[end_time] |\n",
      "                         --filter-nvtx range[@domain][/index] |\n",
      "                         --filter-projected-nvtx range[@domain][/index]]\n",
      "                         [--mode {none,concurrent,dask-futures}]\n",
      "\n",
      "This recipe provides a summary of NVTX time ranges projected from the CPU onto\n",
      "the GPU, and their execution times.\n",
      "\n",
      "options:\n",
      "  -h, --help            Show this help message and exit.\n",
      "\n",
      "Context:\n",
      "  --mode {none,concurrent,dask-futures}\n",
      "                        Mode to run tasks.\n",
      "\n",
      "Recipe:\n",
      "  --output OUTPUT       Output directory name.\n",
      "                        Any %q{ENV_VAR} pattern in the filename will be\n",
      "                        substituted with the value of the environment\n",
      "                        variable.\n",
      "                        Any %h pattern in the filename will be substituted\n",
      "                        with the hostname of the system.\n",
      "                        Any %p pattern in the filename will be substituted\n",
      "                        with the PID.\n",
      "                        Any %n pattern in the filename will be substituted\n",
      "                        with the minimal positive integer that is not already\n",
      "                        occupied.\n",
      "                        Any %% pattern in the filename will be substituted\n",
      "                        with %.\n",
      "  --force-overwrite     Overwrite existing directory.\n",
      "  --input INPUT [INPUT ...]\n",
      "                        One or more paths to nsys-rep files or directories.\n",
      "                        Directories can optionally be followed by ':n' to\n",
      "                        limit the number of files.\n",
      "  --csv                 Additionally output data as CSV.\n",
      "  --filter-time [start_time]/[end_time]\n",
      "                        Filter by time range in nanoseconds.\n",
      "  --filter-nvtx range[@domain][/index]\n",
      "                        Filter by NVTX range using only the start and end\n",
      "                        times of the matching ranges.\n",
      "                        Specify the domain only when the range is not in the\n",
      "                        default domain, or use '*' to include all domains. Any\n",
      "                        '@' or '/' in the names should be escaped with a\n",
      "                        backslash.\n",
      "                        The index is zero-based and is used to select the nth\n",
      "                        range. If no index is specified, all ranges will be\n",
      "                        used.\n",
      "  --filter-projected-nvtx range[@domain][/index]\n",
      "                        Filter by projected NVTX range using only the start\n",
      "                        and end times of the matching ranges.\n",
      "                        Specify the domain only when the range is not in the\n",
      "                        default domain, or use '*' to include all domains. Any\n",
      "                        '@' or '/' in the names should be escaped with a\n",
      "                        backslash.\n",
      "                        The index is zero-based and is used to select the nth\n",
      "                        range. If no index is specified, all ranges will be\n",
      "                        used.\n"
     ]
    }
   ],
   "source": [
    "!nsys recipe nvtx_gpu_proj_sum --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a6dcb",
   "metadata": {},
   "source": [
    "\n",
    "Execute the code cell below to run the *NVTX GPU projection summary* recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e87c6728-c649-43d6-8314-50bfde55e3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:\n",
      "    reports/cvcuda_batchsize\n"
     ]
    }
   ],
   "source": [
    "# !mkdir reports/cvcuda_batchsize\n",
    "\n",
    "!nsys recipe nvtx_gpu_proj_sum \\\n",
    "--output reports/cvcuda_batchsize \\\n",
    "--force-overwrite \\\n",
    "--log-level=error \\\n",
    "--input reports/cvcuda_batchsize\n",
    "\n",
    "# Copy the customized notebook that uses report names instead of ranks.\n",
    "!cp nsys/recipes/nvtx_gpu_proj_sum/topN_files.ipynb reports/cvcuda_batchsize/results_nvtx_gpu_proj_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d567266",
   "metadata": {},
   "source": [
    "After the recipe finishes, open the notebook [reports/cvcuda_batchsize/results_nvtx_gpu_proj_sum/topN_files.ipynb](reports/cvcuda_batchsize/results_nvtx_gpu_proj_sum/topN_files.ipynb) and follow the explanation given in the notebook. You can **use the >> icon** at the top of the tab to execute all the code cells one after another. \n",
    "\n",
    "Below is a screenshot of the statistics table for the top NVTX ranges on the **CPU**.\n",
    "\n",
    "<img src=images/step4/nvtx_recipe_table_cpu_pytorch_.png width=55%>\n",
    "\n",
    "From the table, we can conclude the following:\n",
    "1. The _pipeline_ is fastest when the batch size is 4.\n",
    "2. Inference is the slowest step in the algorithm for batch sizes up to 4. From batch size 8, the encoder step seems to be the slowest step. *(This is the case on the CPU side.)*\n",
    "\n",
    "Going back to the statistics table from the [reports/cvcuda_batchsize/results_nvtx_gpu_proj_sum/topN_files.ipynb](reports/cvcuda_batchsize/results_nvtx_gpu_proj_sum/topN_files.ipynb) to see the top NVTX ranges when projected on the GPU.\n",
    "\n",
    "<img src=images/step4/nvtx_recipe_table_gpu_pytorch_.png width=55%>\n",
    "\n",
    "This shows a clearer picture on the biggest contributor to the _pipeline_'s duration. If we can speed up the inference step's CUDA kernels, we can speed up the _pipeline_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9ea701",
   "metadata": {},
   "source": [
    "## 4.2 Speedup Inference and Verify the Optimization\n",
    "\n",
    "Inference for the segmentation step is done using PyTorch. Alternatively, we can also use [TensorRT](https://developer.nvidia.com/tensorrt) to speed up inference. TensorRT has several accelerations for AI workloads to run faster on NVIDIA GPUs.\n",
    "\n",
    "Execute the cell below to compare the [main_nvtx-cvcuda-nvcodec.py](video_segmentation/main_nvtx-cvcuda-nvcodec.py) and [main_nvtx-cvcuda-trt-nvcodec.py](video_segmentation/main_nvtx-cvcuda-trt-nvcodec.py) files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8783078-f9c4-40d5-8c2e-94077d5d859b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m--- video_segmentation/main_nvtx-cvcuda-nvcodec.py\t2025-05-28 18:13:08.227691625 +0100\u001b[0m\n",
      "\u001b[1m+++ video_segmentation/main_nvtx-cvcuda-trt-nvcodec.py\t2025-05-28 17:17:45.113438177 +0100\u001b[0m\n",
      "\u001b[36m@@ -23,3 +23,2 @@\u001b[0m\n",
      " from nvcodec_utils import BatchEncoder, BatchDecoder\n",
      "\u001b[31m-from multithreading_utils import DecodeThread, EncodeThread\u001b[0m\n",
      " \n",
      "\u001b[36m@@ -29,3 +28,3 @@\u001b[0m\n",
      " # Select inference backend -----------------------------\n",
      "\u001b[31m-from torch_utils import Segmentation\u001b[0m\n",
      "\u001b[32m+from trt_utils import Segmentation\u001b[0m\n",
      " \n"
     ]
    }
   ],
   "source": [
    "!diff -U1 -d --color=always video_segmentation/main_nvtx-cvcuda-nvcodec.py video_segmentation/main_nvtx-cvcuda-trt-nvcodec.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053ac265",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Exercise:</b>\n",
    "<p>Profile the TensorRT version of our sample application <i>video_segmentation/main_nvtx-cvcuda-trt-nvcodec.py</i> with batch size 4.\n",
    "<br>What is the runtime and projected GPU runtime of pipeline, inference and encode now?</p>\n",
    "<p> You can use the following empty code cell.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8020c2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f9d93be-d54e-4d1f-a418-1672178e8f40",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: CPU IP/backtrace sampling not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "WARNING: CPU context switch tracing not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "Invalid plugin configuration: Executable path does not exist: /opt/nvidia/nsight-systems/2025.1.3/target-linux-x64/plugins/mynvml/mynvml_plugin\n",
      "Collecting data...\n",
      "[05/28/2025-19:03:23] [TRT] [E] IRuntime::deserializeCudaEngine: Error Code 1: Internal Error (Failed due to an old deserialization call on a newer plan file. This might happen when the plan file was built from an older TensorRT version. You can use `trtexec --getPlanVersionOnly` to check the version of TensorRT that was used to create the plan file.)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sanjay42/sanjay/cuda/AcceleratedPythonProgramming/video_segmentation/main_nvtx-cvcuda-trt-nvcodec.py\", line 72, in <module>\n",
      "    inference = Segmentation(\"cat\", batch_size, inference_size)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sanjay42/sanjay/cuda/AcceleratedPythonProgramming/video_segmentation/trt_utils.py\", line 124, in __init__\n",
      "    self.model = trt_model.create_execution_context()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'create_execution_context'\n",
      "-------------------------------------------------------------------\n",
      "PyCUDA ERROR: The context stack was not empty upon module cleanup.\n",
      "-------------------------------------------------------------------\n",
      "A context was still active when the context stack was being\n",
      "cleaned up. At this point in our execution, CUDA may already\n",
      "have been deinitialized, so there is no way we can finish\n",
      "cleanly. The program will be aborted now.\n",
      "Use Context.pop() to avoid this problem.\n",
      "-------------------------------------------------------------------\n",
      "Generating '/tmp/nsys-report-624d.qdstrm'\n",
      "[1/1] [========================100%] optimized_cvcuda_trt-nvcodec.nsys-rep\n",
      "Generated:\n",
      "\t/home/sanjay42/sanjay/cuda/AcceleratedPythonProgramming/reports/optimized_cvcuda_trt-nvcodec.nsys-rep\n"
     ]
    }
   ],
   "source": [
    "!nsys profile \\\n",
    "--trace cuda,nvtx,nvvideo \\\n",
    "--cuda-event-trace=false \\\n",
    "--output reports/optimized_cvcuda_trt-nvcodec.nsys-rep \\\n",
    "--force-overwrite=true \\\n",
    "python video_segmentation/main_nvtx-cvcuda-trt-nvcodec.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee1d13ae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating SQLite file reports/optimized_cvcuda_trt-nvcodec.sqlite from reports/optimized_cvcuda_trt-nvcodec.nsys-rep\n",
      "Processing [reports/optimized_cvcuda_trt-nvcodec.sqlite] with [/opt/nvidia/nsight-systems/2025.1.3/host-linux-x64/reports/nvtx_gpu_proj_sum.py]... \n",
      "\n",
      " ** NVTX GPU Projection Summary (nvtx_gpu_proj_sum):\n",
      "\n",
      " Range    Style   Total Proj Time (ns)  Total Range Time (ns)  Range Instances  Proj Avg (ns)  Proj Med (ns)  Proj Min (ns)  Proj Max (ns)  Proj StdDev (ns)  Total GPU Ops  Avg GPU Ops  Avg Range Lvl  Avg Num Child\n",
      " ------  -------  --------------------  ---------------------  ---------------  -------------  -------------  -------------  -------------  ----------------  -------------  -----------  -------------  -------------\n",
      " :total  PushPop               492,510          1,820,007,294                1      492,510.0      492,510.0        492,510        492,510               0.0              2          2.0            0.0            0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nsys stats \\\n",
    "    --report nvtx_gpu_proj_sum \\\n",
    "    --force-export=true \\\n",
    "    reports/optimized_cvcuda_trt-nvcodec.nsys-rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2902d36f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: reports/optimized_cvcuda_trt-nvcodec.nsys-rep: Exporting ['StringIds', 'CUPTI_ACTIVITY_KIND_RUNTIME', 'CUDA_GRAPH_NODE_EVENTS', 'CUDA_GRAPH_EVENTS', 'CUPTI_ACTIVITY_KIND_KERNEL', 'CUPTI_ACTIVITY_KIND_MEMCPY', 'CUPTI_ACTIVITY_KIND_MEMSET', 'CUPTI_ACTIVITY_KIND_GRAPH_TRACE', 'NVTX_EVENTS'] to reports/optimized_cvcuda_trt-nvcodec_pqtdir...\n",
      "Generated:\n",
      "    reports/results-nvtx-trt\n"
     ]
    }
   ],
   "source": [
    "!nsys recipe \\\n",
    "    nvtx_gpu_proj_sum \\\n",
    "    --input=reports/optimized_cvcuda_trt-nvcodec.nsys-rep \\\n",
    "    --output=reports/results-nvtx-trt \\\n",
    "    --force-overwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ccd0e9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The two commands above can both be used to determine the NVTX GPU projection times.\n",
    "\n",
    "Statistics for a report can be created and visualized via the `nsys stats` command on the command line or via the _Stats System View_ in the Nsight Systems GUI.\n",
    "The following screenshot shows the NVTX GPU projection statistics view in the Nsight Systems GUI:\n",
    "<img src=images/step4/nvtx_gpu_proj_stats_trt.png>\n",
    "\n",
    "`nsys recipe` can also be used on a single report.\n",
    "This is the output of the NVTX GPU projection recipe:\n",
    "<table style=\"float: left\">\n",
    "<colgroup>\n",
    "       <col span=\"1\" style=\"width: 50%;\">\n",
    "       <col span=\"1\" style=\"width: 25%;\">\n",
    "    </colgroup>\n",
    "<tr>\n",
    "<td>\n",
    "<img src=images/step4/nvtx_gpu_proj_trt_recipe_barchart.png>\n",
    "</td>\n",
    "<td>\n",
    "<img src=images/step4/nvtx_gpu_proj_trt_recipe_table.png>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "With increasing batch sizes the _encode_ step becomes the bottleneck. We will stop here as we have already achieved a significant speedup.\n",
    "The _pipeline_ stage is now down to ~2.7s which is a speedup of 2.1x compared to the previous optimization step and 27.8x to the baseline code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9882e3b5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Summary</b>\n",
    "    <p>\n",
    "        We used the multi-report analysis feature of Nsight Systems to compare the performance of runs with different batch sizes.\n",
    "    </p>\n",
    "    <p>\n",
    "        We learned about how Nsight Systems is doing NVTX range projection to the GPU workload.\n",
    "    </p>\n",
    "    <p>\n",
    "        We applied another optimization to speed-up the CV-CUDA pipeline.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d0e8b8",
   "metadata": {},
   "source": [
    "Click [here](step5.ipynb) to move to the next step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
